{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "nA9Y7ga8ng1Z",
        "dauF4eBmngu3",
        "GF8Ens_Soomf",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "id1riN9m0vUs",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankijoshi2011/Credit-card-Default-Predictiontion/blob/main/Credit_Card_Default_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name -** Akanksha Joshi"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Credit card default prediction is like foreseeing whether someone might have trouble paying their credit card bills on time. This is important because when people can't pay, banks lose money. By using clever computer models, banks can guess who might struggle to pay and help them before things get worse. This helps banks save money, use their resources better, and keep their customers happy. It's like giving a heads-up to both the bank and the customers to prevent money troubles and make things work smoothly for everyone.\n",
        "\n",
        "The \"Credit Card Default Prediction\" project aims to develop a predictive model for identifying potential credit card defaulters using historical transaction data and customer information. By accurately assessing the likelihood of default, the project aims to reduce financial losses, improve resource allocation, and enhance customer relationships through proactive measures. The project involves data collection, preprocessing, feature engineering, model selection, training, and validation. The chosen model will be integrated into operational systems to enable early risk identification and tailored interventions. Successful implementation is expected to mitigate risks, lower costs, increase customer satisfaction, and enhance overall operational efficiency within the credit card industry."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/ankijoshi2011/Credit-card-Default-Predictiontion"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The challenge at hand is to create a reliable system for predicting credit card defaults. This system needs to use historical data and customer details to forecast if someone is likely to have difficulty paying their credit card bills on time. By doing this, we aim to help banks and financial institutions avoid losing money due to unpaid bills. We also want to assist customers by giving them early support to manage their finances better. This project requires developing smart models that can analyze patterns and make predictions."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import scipy.stats as stats\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, roc_auc_score,f1_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "J5Q8m80B9b_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "df=pd.read_excel('/content/drive/MyDrive/data/default of credit card clients.xlsx')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "OWVeetQbvEVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isna())"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset has 3000 Rows and 25 columns. All the columns are integer data type. There are no null or duplicated values in the data."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ID:** An identifier for each individual in the dataset. This is likely not directly related to credit card default prediction but can be useful for tracking and indexing individuals.\n",
        "\n",
        "**LIMIT_BAL:** The credit limit granted to the individual by the credit card company. A higher credit limit might indicate a greater ability to manage credit, but it could also lead to higher potential debt.\n",
        "\n",
        "**SEX:** Gender of the individual. This could potentially impact their financial behaviors, but gender alone is unlikely to be a strong predictor of credit card default.(1 = male; 2 = female)\n",
        "\n",
        "**EDUCATION:** Educational background of the individual. Education might influence financial literacy and income, which could impact credit behavior.Education (1 = graduate school; 2 = university; 3 = high school; 4 = others).\n",
        "\n",
        "**MARRIAGE:** Marital status of the individual(1 = married; 2 = single; 3 = others). Similar to gender, marital status alone might not be a strong predictor, but it could be related to financial stability.\n",
        "\n",
        "**AGE:** Age of the individual. Younger individuals might have less financial experience and stability, potentially leading to higher default rates.\n",
        "\n",
        "**PAY_0, PAY_2, PAY_3, PAY_4, PAY_5, PAY_6:** Repayment status of the credit card for the last six months. These variables can give insight into the payment history of the individual. A history of late payments might suggest an increased risk of default ( -1 = pay duly; 1 = payment delay for one month; 2 = payment delay for two months; . . .; 8 = payment delay for eight months; 9 = payment delay for nine months and above.)\n",
        "\n",
        "**BILL_AMT1, BILL_AMT2, BILL_AMT3, BILL_AMT4, BILL_AMT5, BILL_AMT6:** Billing amounts for the credit card for the last six months. These can indicate the individual's credit card usage and debt accumulation over time.\n",
        "\n",
        "**PAY_AMT1, PAY_AMT2, PAY_AMT3, PAY_AMT4, PAY_AMT5, PAY_AMT6:** Payment amounts made by the individual for the credit card for the last six months. Timely and sufficient payments might indicate responsible credit behavior.\n",
        "\n",
        "**default_payment_next_month:** The target variable. This binary variable (Yes = 1, No = 0) indicates whether the individual defaulted on their credit card payment in the next month. This is the variable Iam trying to predict.\n",
        "\n",
        "In the context of credit card default prediction, features related to payment history, credit utilization (billing amounts), and payment behavior are likely to be strong predictors. Variables like age, education, and marital status might also play a role. However, building an effective prediction model would involve analyzing the relationships between these variables and the target variable through techniques such as exploratory data analysis, feature engineering, and machine learning algorithms."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['SEX'].value_counts()"
      ],
      "metadata": {
        "id": "nW8QkuocwGOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['EDUCATION'].value_counts()"
      ],
      "metadata": {
        "id": "wcD5TGmwxPAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['MARRIAGE'].value_counts()"
      ],
      "metadata": {
        "id": "7cufWfdBxY9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see that there are more varities in the education column as well as in marital status column. Definitely that needs to be fixed."
      ],
      "metadata": {
        "id": "BF4f6Z3nyzJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fixing 'EDUCATION' column by replacing the 0,5,6 category with 4\n",
        "edu = (df.EDUCATION == 5) | (df.EDUCATION == 6) | (df.EDUCATION == 0)\n",
        "df.loc[edu, 'EDUCATION'] = 4\n",
        "\n",
        "# Fixing 'MARRIAGE' column by replacing the 0 or unknown category with 3\n",
        "df.loc[df.MARRIAGE == 0, 'MARRIAGE'] = 3"
      ],
      "metadata": {
        "id": "qyX097Tpytjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pay_status_columns = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
        "\n",
        "# Replace -1 and -2 with -1 in the pay status columns\n",
        "df[pay_status_columns] = df[pay_status_columns].replace([-1, -2], 0)"
      ],
      "metadata": {
        "id": "_wq-HCqrERUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['ID'])"
      ],
      "metadata": {
        "id": "WoPvb3OQFp4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The Id column was deleted since it has no importance in the analysis. There are three categorical variables in the data as 'gender', 'education','marital status'. The gender column has only two values as 1 and 2 which is fine. But there were more varities in the information under education and marital status. so I have replaced the unknown values in those columns with the category values which have lowest number of values after them.All the pay status column are having three values as -1,0,-2 indicating as payment was made in time which corresponds to no delay.Also all the pay status column are having three values as -1,0,-2 indicating as payment was made in time which corresponds to no delay.so I have replaced these no delays of payment with one perticular value as -1 to have a clear understanding."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['default_payment_next_month'].value_counts()"
      ],
      "metadata": {
        "id": "PJRWHLRtk9fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.pie(df['default_payment_next_month'].value_counts(),autopct='%1.2f%%')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "htToEOcfIu2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A pie chart visually represents the proportional distribution of data categories, making it easy to grasp the relative sizes or percentages of each category at a glance, aiding in quick comparisons and identifying dominant categories in a dataset."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.12 % people out of 30,000 dataset are defaulters."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stratergies to be made to reduce the number of defaulters."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# Filter the DataFrame for rows where 'default_payment_next_month' is 1\n",
        "defaulted_df = df[df['default_payment_next_month'] == 1]\n",
        "\n",
        "# Count the number of males and females in the filtered DataFrame\n",
        "male_count = defaulted_df[defaulted_df['SEX'] == 1]['SEX'].count()\n",
        "female_count = defaulted_df[defaulted_df['SEX'] == 2]['SEX'].count()\n",
        "\n",
        "# Create a bar plot\n",
        "labels = ['Male', 'Female']\n",
        "counts = [male_count, female_count]\n",
        "\n",
        "plt.bar(labels, counts, color=['blue', 'pink'])\n",
        "plt.xlabel('Gender')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of Defaults by Gender')\n",
        "plt.show()\n",
        "#This code creates a bar plot with 'Male' and 'Female' on the x-axis and the respective counts on the y-axis, showing the number of defaults for each gender. You can customize the plot further to match your preferences.\n",
        "\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is effective for comparing and displaying discrete data categories or values, allowing for clear visualization of differences in magnitude, making it useful for showing trends, comparisons, and ranking of data in a straightforward and easily interpretable manner."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The defaulters can not be told as per gender, they are almost equal"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "education_counts = defaulted_df['EDUCATION'].value_counts().sort_index()\n",
        "\n",
        "# Define labels for the education categories (you can replace these with actual category names)\n",
        "education_labels = ['Graduate School', 'University', 'High School', 'Others']\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(education_labels, education_counts)\n",
        "plt.xlabel('Education Category')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of Defaults by Education Category')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Max defaulters are from University and graduate school education category"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "marriage_counts = defaulted_df['MARRIAGE'].value_counts().sort_index()\n",
        "\n",
        "# Define labels for the marriage categories (you can replace these with actual category names)\n",
        "marriage_labels = ['Married', 'Single', 'Others']\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(marriage_labels, marriage_counts)\n",
        "plt.xlabel('Marriage Category')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Number of Defaults by Marriage Category')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cGzi-FHbP_cZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Married and single category are equal defaulters in contribution."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chart - 5"
      ],
      "metadata": {
        "id": "ieZFpdaVP919"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "# Define the age groups\n",
        "age_groups = {\n",
        "    '30-40': (30, 40),\n",
        "    '40-50': (40, 50),\n",
        "    '50-60': (50, 60),\n",
        "    '60-70': (60, 70)\n",
        "}\n",
        "\n",
        "# Create an empty dictionary to store the counts for each age group\n",
        "default_counts = {}\n",
        "\n",
        "# Loop through the age groups and count the defaulters\n",
        "for group, (min_age, max_age) in age_groups.items():\n",
        "    filtered_df = df[(df['AGE'] >= min_age) & (df['AGE'] < max_age) & (df['default_payment_next_month'] == 1)]\n",
        "    default_counts[group] = len(filtered_df)\n",
        "\n",
        "\n",
        "# Create a bar plot\n",
        "plt.bar(default_counts.keys(), default_counts.values())\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Number of Defaulters')\n",
        "plt.title('Number of Defaulters in Different Age Groups')\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8U8EFL7dP6QF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Chart - 6"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['limit']=df['LIMIT_BAL']/10000"
      ],
      "metadata": {
        "id": "HsdX3kkfDFsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "for col in ['limit','AGE']:\n",
        "    fig = plt.figure(figsize=(9, 6))\n",
        "    ax = fig.gca()\n",
        "    feature = df[col]\n",
        "    feature.hist(bins=50, ax = ax)\n",
        "    ax.axvline(feature.mean(), color='Red', linestyle='dashed', linewidth=2)\n",
        "    ax.axvline(feature.median(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "    ax.set_title(col)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As histogram is a very popular tool so the chart will show the overview of each and every varriables information and gives a clear idea about the data set. It also sumarizes the measured data."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Red line represents the mean of the data and mergenta line represents the median. In the above plots it is clearly visible that average balance limit (CREDIT LIMIT) is 15-16 thousands.Average Age od dataset is around 36-37 years.\n",
        "\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 07 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize= (20,15))\n",
        "sns.heatmap(df.corr(), annot=True)\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To check Multicolinearity."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above corelation plot we can see that bill_april to september columns are highly correlated to each other which makes sense as these columns indicates the bill amounts.\n",
        "\n",
        "\n",
        "Apart from that there are no highly correlated inputs in our dataset, so there is no multicollinearity problem."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As checked there are no missing values"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "fig = plt.figure(figsize=(16,32))\n",
        "c=1\n",
        "for i in df.columns :\n",
        "    plt.subplot(7, 3, c)\n",
        "    plt.xlabel('Distibution of {}'.format(i))\n",
        "    sns.boxplot(x=i,data=df)\n",
        "    if c==21 :\n",
        "      c = c + 0\n",
        "    else :\n",
        "      c=c+1\n",
        "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are outliers detected in the columns - Limit Bal, Education(Category- others) and Age(60+)\n",
        "These outliers can not be removed as they play an important role in model accuracy."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "dum=pd.get_dummies(df['SEX'])\n",
        "df=pd.concat([df,dum],axis=1)\n",
        "df = df.rename(columns={1: 'MALE', 2: 'FEMALE', 'default_payment_next_month' : 'default'})\n"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dum=pd.get_dummies(df['MARRIAGE'])\n",
        "df=pd.concat([df,dum],axis=1)\n",
        "df=df.rename(columns={1: 'Married', 2: 'Single', 3:'others'})\n",
        "\n"
      ],
      "metadata": {
        "id": "MRKXWCYiZ8sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dum=pd.get_dummies(df['EDUCATION'])\n",
        "df=pd.concat([df,dum],axis=1)\n",
        "df=df.rename(columns={1: 'graduate school', 2: 'university', 3: 'high school'})\n",
        "\n",
        "df.drop(columns=['others', 4, 'SEX', 'EDUCATION', 'MARRIAGE', 'limit'], inplace=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "jqOCbsXIanKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "ljZHnsm6Vuj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used dummification to do categorical encoding for the columns - SEX,EDUCATION and MARITAL STATUS"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "X = df.drop(labels='default', axis=1)\n",
        "Y = df['default']"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the shape of X and Y\n",
        "print(f\"The Number of Rows and Columns in X is {X.shape} respectively.\")\n",
        "print(f\"The Number of Rows and Columns in Y is {Y.shape} respectively.\")"
      ],
      "metadata": {
        "id": "bbQJcXkNilN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The StandardScaler is used in machine learning to standardize numerical features by centering them around zero and scaling them to have a standard deviation of 1. This preprocessing step ensures that all features contribute equally to model training, improving the performance of algorithms sensitive to feature scales. It aids convergence in algorithms like support vector machines and enhances visualization. StandardScaler is particularly helpful when dealing with features of different units or scales, promoting consistent and stable model behavior. However, not all algorithms require standardization, and its usage depends on the specific problem and data characteristics."
      ],
      "metadata": {
        "id": "dYPYCefWi6IP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split( X , Y , test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A 80:20 test-train data split ratio strikes a balance between having sufficient training data for model learning and a substantial test set for robust evaluation, facilitating both model development and performance assessment. However, the choice of ratio should consider specific dataset characteristics and project requirements."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=6, weights='distance')\n",
        "\n",
        "# Fit the Algorithm\n",
        "knn.fit(X_train, Y_train)\n",
        "\n",
        "# Predict on the model\n",
        "knn_y_pred_train = knn.predict(X_train)\n",
        "knn_tree_y_pred_test = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wd1qcGPHpoyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "print('Untuned K Nearest Neighbors Model')\n",
        "print(\"Training F1 Score: \", metrics.f1_score(Y_train, knn_y_pred_train))\n",
        "print(\"Testing F1 Score: \", metrics.f1_score(Y_test, knn_tree_y_pred_test))\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "k_near = KNeighborsClassifier(weights='distance')\n",
        "# Fit the Algorithm\n",
        "k_param_dict={'n_neighbors': range(4,15,1)}\n",
        "grid_k_neighbors = GridSearchCV(k_near, k_param_dict, cv=5, scoring='f1', verbose=1)\n",
        "grid_k_neighbors.fit(X_train, Y_train)\n",
        "# Predict on the model\n",
        "print('F1 Score:', grid_k_neighbors.best_score_)\n",
        "print('Best Hyperparameters:', grid_k_neighbors.best_params_)\n",
        "print('Model object with best parameters: ')\n",
        "print(grid_k_neighbors.best_estimator_)"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting the response on both train and test data set respectively.\n",
        "tuned_k_neighbors_y_pred_train = grid_k_neighbors.best_estimator_.predict(X_train)\n",
        "tuned_k_neighbors_y_pred_test = grid_k_neighbors.best_estimator_.predict(X_test)\n",
        "\n",
        "print('Tuned K Nearest Neighbors Predictions')\n",
        "print(\"F1 on train set:\",metrics.f1_score(Y_train, tuned_k_neighbors_y_pred_train))\n",
        "print(\"F1 on test set:\",metrics.f1_score(Y_test, tuned_k_neighbors_y_pred_test))"
      ],
      "metadata": {
        "id": "r4N052WWtOYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since hyperparameter values are predefined so here grid search technique has been used to tune the hyper paramenter.\n"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Very slight improvement but this will not help. An F1 score of 0.27 for the test data and 0.99 for the train data suggests a significant disparity in model performance between the training and testing datasets. A high F1 score on the training data (0.99) indicates that the model has likely overfitted the training data, capturing it almost perfectly, but it fails to generalize well to unseen data, as evidenced by the much lower F1 score on the test data (0.27). This discrepancy indicates a potential issue of overfitting, where the model is overly complex and lacks the ability to generalize to new examples effectively."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "logreg = LogisticRegression(C=1e9, class_weight='balanced')\n",
        "logreg.fit(X_train, Y_train)\n",
        "logreg_y_pred_train = logreg.predict(X_train)\n",
        "logreg_y_pred_test = logreg.predict(X_test)\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Untuned Logistic Regression Model')\n",
        "print(\"Training F1 Score: \", metrics.f1_score(Y_train, logreg_y_pred_train))\n",
        "print(\"Testing F1 Score: \", metrics.f1_score(Y_test, logreg_y_pred_test))"
      ],
      "metadata": {
        "id": "OnEQkqIrudzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = logreg.predict_proba(X_test)[:, 1]\n",
        "fpr, tpr, thresholds = metrics.roc_curve(Y_test, y_pred_prob)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.title('ROC curve for Logisitic Regression')\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "plt.grid(True)"
      ],
      "metadata": {
        "id": "2PX2D9r-uxqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(metrics.roc_auc_score(Y_test, y_pred_prob))"
      ],
      "metadata": {
        "id": "pHz_aZxOvasC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy:', metrics.accuracy_score(Y_test, logreg_y_pred_test))\n",
        "print('precision:', metrics.precision_score(Y_test, logreg_y_pred_test))\n",
        "print('recall:', metrics.recall_score(Y_test, logreg_y_pred_test))\n",
        "print('f1 score:', metrics.f1_score(Y_test, logreg_y_pred_test))"
      ],
      "metadata": {
        "id": "O4A7asiNvaoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# confusion matrix\n",
        "labels = ['Not default', 'default']\n",
        "cm = confusion_matrix(Y_train, logreg_y_pred_train)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix for Train data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "XMMuHV7Zvalu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['Not default', 'default']\n",
        "cm = confusion_matrix(Y_test, logreg_y_pred_test)\n",
        "print(cm)\n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix for Test data')\n",
        "ax.xaxis.set_ticklabels(labels)\n",
        "ax.yaxis.set_ticklabels(labels)"
      ],
      "metadata": {
        "id": "lgG3whqWvajU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "pkbVCg76y66I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "tuned_log = LogisticRegression(random_state=42, class_weight='balanced')\n",
        "# Fit the Algorithm\n",
        "log_param_dict={'C': range(3,7,1),\n",
        "                'penalty': ['l1','l2']}\n",
        "grid_log = GridSearchCV(tuned_log, log_param_dict, cv=5, scoring='f1', verbose=1)\n",
        "grid_log.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('F1 Score:', grid_log.best_score_)\n",
        "print('Best Hyperparameters:', grid_log.best_params_)\n",
        "print('Model object with best parameters: ')\n",
        "print(grid_log.best_estimator_)"
      ],
      "metadata": {
        "id": "vObnLMKXyJgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_log_y_pred_train = grid_log.best_estimator_.predict(X_train)\n",
        "grid_log_y_pred_test = grid_log.best_estimator_.predict(X_test)\n",
        "\n",
        "print('Tuned Logistic Regression Model Predictions')\n",
        "print(\"F1 on train set:\",metrics.f1_score(Y_train, grid_log_y_pred_train))\n",
        "print(\"F1 on test set:\",metrics.f1_score(Y_test, grid_log_y_pred_test))"
      ],
      "metadata": {
        "id": "64mZNt_hyOGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}